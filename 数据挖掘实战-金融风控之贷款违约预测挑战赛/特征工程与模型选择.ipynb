{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382655f5-2b24-4dab-929d-31b558fb4e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt    \n",
    "import seaborn as sns    \n",
    "import datetime    \n",
    "from tqdm import tqdm    \n",
    "from sklearn.preprocessing import LabelEncoder    \n",
    "from sklearn.feature_selection import SelectKBest    \n",
    "from sklearn.feature_selection import chi2    \n",
    "from sklearn.preprocessing import MinMaxScaler    \n",
    "import xgboost as xgb    \n",
    "import lightgbm as lgb    \n",
    "from catboost import CatBoostRegressor    \n",
    "import warnings    \n",
    "from sklearn.model_selection import StratifiedKFold, KFold    \n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss    \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778fa77-c481-4550-895d-537644a11ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train =pd.read_csv('train.csv')    \n",
    "data_test_a = pd.read_csv('testA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae5a18-1026-40c3-b528-05278000d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_features = ['employmentTitle', 'homeOwnership', 'verificationStatus', 'purpose', 'postCode', 'regionCode',     \n",
    "                 'applicationType', 'initialListStatus', 'title', 'policyCode']\n",
    "numerical_fea = [i for i in data_train.columns if i not in cate_features]\n",
    "# category_fea = list(filter(lambda x: x not in numerical_fea,list(data_train.columns)))    \n",
    "label = 'isDefault'    \n",
    "numerical_fea.remove(label)\n",
    "numerical_fea.remove('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828367b1-ab4a-4eea-b9e4-fca09d508a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e1222-c713-4da9-8b36-434f771e85c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec087b-7008-4a91-a1e1-c8e73006d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#按照平均数填充数值型特征    \n",
    "data_train[numerical_fea] = data_train[numerical_fea].fillna(data_train[numerical_fea].median())    \n",
    "data_test_a[numerical_fea] = data_test_a[numerical_fea].fillna(data_train[numerical_fea].median())    \n",
    "#按照众数填充类别型特征    \n",
    "data_train[category_fea] = data_train[category_fea].fillna(data_train[category_fea].mode())    \n",
    "data_test_a[category_fea] = data_test_a[category_fea].fillna(data_train[category_fea].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e029be6-a3d0-449b-a77b-9154dc274f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224c329-73d8-43f9-a114-778c788d42b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def employmentLength_to_int(s):    \n",
    "    if pd.isnull(s):    \n",
    "        return s    \n",
    "    else:    \n",
    "        return np.int8(s.split()[0])    \n",
    "for data in [data_train, data_test_a]:    \n",
    "    data['employmentLength'].replace(to_replace='10+ years', value='10 years', inplace=True)    \n",
    "    data['employmentLength'].replace('< 1 year', '0 years', inplace=True)    \n",
    "    data['employmentLength'] = data['employmentLength'].apply(employmentLength_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2196ed94-8744-47ba-832f-306def3c430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用前五后五的拉格朗日函数值去fillna\n",
    "#定义插值函数,取值时数据范围不能超过data的边界\n",
    "from scipy.interpolate import lagrange\n",
    "def insert_value(s, n, k=5):\n",
    "    if n >= 5 and n+k+1 < len(s):\n",
    "        y = s[list(range(n-k,n))+list(range(n+1,n+k+1))]\n",
    "        y = y[y.notnull()]\n",
    "        insert_value = lagrange(y.index, list(y))(n)\n",
    "    elif n < 5:\n",
    "        y = s[list(range(0,n))+list(range(n+1,n+k+1))]\n",
    "        y = y[y.notnull()]\n",
    "        insert_value = lagrange(y.index, list(y))(n)\n",
    "    elif n+k+1 >= len(s):\n",
    "        y = s[list(range(n-k,n))+list(range(n+1,len(s)))]\n",
    "        y = y[y.notnull()]\n",
    "        insert_value = lagrange(y.index, list(y))(n) > 0\n",
    "    return round(insert_value,1)\n",
    "    \n",
    "def fillna_method(data, columns):\n",
    "    for i in columns:\n",
    "        for j in range(len(data)):\n",
    "            if data[i].isnull()[j]:\n",
    "                if insert_value(data[i],j) < 0: \n",
    "                    data[i][j] = 0\n",
    "                elif insert_value(data[i],j) < 10:\n",
    "                    data[i][j] = insert_value(data[i],j)\n",
    "                elif insert_value(data[i],j) < 15:\n",
    "                    data[i][j] = 10\n",
    "                else:\n",
    "                    print(i, j, insert_value(data[i],j))\n",
    "                    break\n",
    "                    \n",
    "#采用线性插值法进行填充，并四舍五入              \n",
    "for data in [data_train, data_test_a]:\n",
    "    data['employmentLength'] = round(data['employmentLength'].interpolate(method='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280d476-e3dd-43ce-8441-78911eaf71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c55e2-0a3d-4936-9b5d-2f868a77862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对数值型特征进行标准化\n",
    "import sklearn.preprocessing as preproc\n",
    "cate_features = ['employmentTitle', 'homeOwnership', 'verificationStatus', 'purpose', 'postCode', 'regionCode',     \n",
    "                 'applicationType', 'initialListStatus', 'title', 'policyCode']\n",
    "numerical_fea = list(data_train.select_dtypes(exclude=['object']).columns)\n",
    "numerical_fea = [i for i in numerical_fea if i not in cate_features]\n",
    "numerical_fea.remove(label)\n",
    "numerical_fea.remove('id')\n",
    "\n",
    "\n",
    "zscore_scaler=preproc.StandardScaler()\n",
    "for data in [data_train, data_test_a]:\n",
    "    data[numerical_fea] = zscore_scaler.fit_transform(data[numerical_fea])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339814cc-4ff0-48af-9bd8-cc8f18e6d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Objetct特征处理['grade', 'subGrade', 'employmentLength', 'issueDate', 'earliesCreditLine']\n",
    "#'employmentLength'上面已经处理\n",
    "#日期特征处理：\n",
    "#'issueDate'\n",
    "for data in [data_train, data_test_a]:    \n",
    "    data['issueDate'] = pd.to_datetime(data['issueDate'],format='%Y-%m-%d')    \n",
    "    startdate = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')    \n",
    "    #构造时间特征    \n",
    "    data['issueDate'] = data['issueDate'].apply(lambda x: x-startdate).dt.days\n",
    "\n",
    "#'earliesCreditLine'\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def calculate_months_diff(x):\n",
    "    date_diff = relativedelta(datetime.datetime.strptime('2023-12', '%Y-%m'),datetime.datetime.strptime('Sep-1999', '%b-%Y'))\n",
    "    return date_diff.years*12+date_diff.months\n",
    "\n",
    "for data in [data_train, data_test_a]:\n",
    "    data['earliesCreditLine'] = data['earliesCreditLine'].apply(lambda x:calculate_months_diff(x))\n",
    "\n",
    "#其他object特征处理    \n",
    "#像grade这种类别特征，是有优先级的可以labelencode或者自映射\n",
    "for data in [data_train, data_test_a]:    \n",
    "    data['grade'] = data['grade'].map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'G':7})   \n",
    "    \n",
    "#subgrade同理\n",
    "d = {}\n",
    "for index, value in enumerate(sorted(data_train['subGrade'].unique())):\n",
    "    d[value] = index+1\n",
    "for data in [data_train, data_test_a]:    \n",
    "    data['subGrade'] = data['subGrade'].map(d)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85db58a8-9bd4-43ba-848e-9414c9413e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#类别特征处理    \n",
    "cate_features = ['employmentTitle', 'homeOwnership', 'verificationStatus', 'purpose', 'postCode', 'regionCode',     \n",
    "                 'applicationType', 'initialListStatus', 'title', 'policyCode']    \n",
    "for f in cate_features:    \n",
    "    print(f, '类型数：', data[f].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1afcf6-54ee-4772-ad36-19f3fe214c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类型数在2之上，又不是高维稀疏的,且纯分类特征    \n",
    "data_train = pd.get_dummies(data_train, columns=['homeOwnership', 'verificationStatus', 'purpose', 'regionCode'], drop_first=True)\n",
    "data_test_a = pd.get_dummies(data_test_a, columns=['homeOwnership', 'verificationStatus', 'purpose', 'regionCode'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c287f7-e20b-4c17-af8e-722e2f47f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0399c4cb-05b9-4d26-a9a1-66f689b46025",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d0a000-86e0-4a66-8d4f-44ee479913a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#内存管理\n",
    "import sys\n",
    "\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b311d43b-be72-4615-b8d3-a6ea700b2e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trigger garbage collection\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b7f15-cd23-4e5d-a06d-6558f1348811",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_train.columns.tolist()\n",
    "features.remove('id')\n",
    "features.remove('isDefault')\n",
    "train_x = data_train[features]\n",
    "valid_x = data_test_a[features]\n",
    "train_y = data_train['isDefault']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95cbc20-3da4-45c0-9c79-fa2a5faaece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#自动特征工程\n",
    "from openfe import OpenFE, transform\n",
    "ofe = OpenFE()\n",
    "n_jobs = 5\n",
    "features = ofe.fit(data=train_x, label=train_y, n_jobs=n_jobs)  # generate new features\n",
    "train_x, valid_x = transform(train_x, valid_x, features, n_jobs=n_jobs) # transform the train and test data according to generated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44320844-63bd-455f-9701-1ca74d26ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name):    \n",
    "    folds = 5    \n",
    "    seed = 2020    \n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)    \n",
    "\n",
    "    train = np.zeros(train_x.shape[0])    \n",
    "    test = np.zeros(test_x.shape[0])    \n",
    "\n",
    "    cv_scores = []    \n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):    \n",
    "        print('************************************ {} ************************************'.format(str(i+1)))    \n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]    \n",
    "\n",
    "        if clf_name == \"lgb\":    \n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y)    \n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y)    \n",
    "\n",
    "            params = {    \n",
    "                'boosting_type': 'gbdt',    \n",
    "                'objective': 'binary',    \n",
    "                'metric': 'auc',    \n",
    "                'num_leaves': 33,    \n",
    "                'max_depth': 6,    \n",
    "                'min_data_in_leaf':45,    \n",
    "                'min_child_weight':0.001,    \n",
    "                'bagging_fraction': 0.9,    \n",
    "                'feature_fraction': 0.9,    \n",
    "                'bagging_freq': 10,    \n",
    "                'min_split_gain': 0.1,    \n",
    "                'reg_lambda':0.01,    \n",
    "                'reg_alpha':0.08,    \n",
    "                'learning_rate': 0.01,    \n",
    "                'seed': 2020,    \n",
    "                'nthread': 24,    \n",
    "                'n_jobs':24,    \n",
    "                'silent': True,    \n",
    "                'verbose': -1,  \n",
    "            }    \n",
    "\n",
    "            model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=200,early_stopping_rounds=200)    \n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration)    \n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration)    \n",
    "\n",
    "            # print(list(sorted(zip(features, model.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True))[:20])    \n",
    "\n",
    "        if clf_name == \"xgb\":    \n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y)    \n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y)    \n",
    "\n",
    "            params = {'booster': 'gbtree',    \n",
    "                      'objective': 'binary:logistic',    \n",
    "                      'eval_metric': 'auc',    \n",
    "                      'gamma': 1,    \n",
    "                      'min_child_weight': 1.5,    \n",
    "                      'max_depth': 5,    \n",
    "                      'lambda': 10,    \n",
    "                      'subsample': 0.7,    \n",
    "                      'colsample_bytree': 0.7,    \n",
    "                      'colsample_bylevel': 0.7,    \n",
    "                      'eta': 0.04,    \n",
    "                      'tree_method': 'exact',    \n",
    "                      'seed': 2020,    \n",
    "                      'nthread': 36,    \n",
    "                      \"silent\": True,    \n",
    "                      }    \n",
    "\n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]    \n",
    "\n",
    "            model = clf.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=200, early_stopping_rounds=200)    \n",
    "            val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)    \n",
    "            test_pred = model.predict(test_x , ntree_limit=model.best_ntree_limit)    \n",
    "\n",
    "        if clf_name == \"cat\":    \n",
    "            params = {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',    \n",
    "                      'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False}    \n",
    "\n",
    "            model = clf(iterations=20000, **params)    \n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),    \n",
    "                      cat_features=[], use_best_model=True, verbose=500)    \n",
    "\n",
    "            val_pred  = model.predict(val_x)    \n",
    "            test_pred = model.predict(test_x)    \n",
    "\n",
    "        train[valid_index] = val_pred    \n",
    "        test = test_pred / kf.n_splits    \n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))    \n",
    "\n",
    "        print(cv_scores)    \n",
    "\n",
    "    print(\"%s_scotrainre_list:\" % clf_name, cv_scores)    \n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))    \n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de735182-6092-4d08-ae5c-be1ff6be2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(x_train, y_train, x_test):    \n",
    "    lgb_train, lgb_test = cv_model(lgb, x_train, y_train, x_test, \"lgb\")    \n",
    "    return lgb_train, lgb_test    \n",
    "\n",
    "def xgb_model(x_train, y_train, x_test):    \n",
    "    xgb_train, xgb_test = cv_model(xgb, x_train, y_train, x_test, \"xgb\")    \n",
    "    return xgb_train, xgb_test    \n",
    "\n",
    "def cat_model(x_train, y_train, x_test):    \n",
    "    cat_train, cat_test = cv_model(CatBoostRegressor, x_train, y_train, x_test, \"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e25b4-dee1-4064-a4b3-76acfa796e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb_train, lgb_test = lgb_model(train_x, train_y, valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b91723-10c4-43c1-8c68-8c4d77eaeea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#结果保存\n",
    "# lgb_result.to_pickle('lgb_result.pickle')\n",
    "#submit结果拼接\n",
    "lgb_submit = pd.DataFrame([[data_test_a['id'][i], lgb_test[i]] for i in range(len(lgb_test))], columns=['id', 'isDefault'])\n",
    "lgb_submit.to_csv('lgb_test2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860899a-564e-45ea-992d-f7e8d9506f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#网格调参，基础模型为lightgbm\n",
    "from sklearn.model_selection import GridSearchCV    \n",
    "\n",
    "def get_best_cv_params(learning_rate=0.1, n_estimators=581, num_leaves=31, max_depth=-1, bagging_fraction=1.0,    \n",
    "                       feature_fraction=1.0, bagging_freq=0, min_data_in_leaf=20, min_child_weight=0.001,    \n",
    "                       min_split_gain=0, reg_lambda=0, reg_alpha=0, param_grid=None,\n",
    "                      X_train=train_x, y_train=train_y):    \n",
    "    # 设置5折交叉验证    \n",
    "    cv_fold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True, )    \n",
    "\n",
    "    model_lgb = lgb.LGBMClassifier(learning_rate=learning_rate,    \n",
    "                                   n_estimators=n_estimators,    \n",
    "                                   num_leaves=num_leaves,    \n",
    "                                   max_depth=max_depth,    \n",
    "                                   bagging_fraction=bagging_fraction,    \n",
    "                                   feature_fraction=feature_fraction,    \n",
    "                                   bagging_freq=bagging_freq,    \n",
    "                                   min_data_in_leaf=min_data_in_leaf,    \n",
    "                                   min_child_weight=min_child_weight,    \n",
    "                                   min_split_gain=min_split_gain,    \n",
    "                                   reg_lambda=reg_lambda,    \n",
    "                                   reg_alpha=reg_alpha,    \n",
    "                                   n_jobs= 8    \n",
    "                                  )    \n",
    "    grid_search = GridSearchCV(estimator=model_lgb,    \n",
    "                               cv=cv_fold,    \n",
    "                               param_grid=param_grid,    \n",
    "                               scoring='roc_auc'    \n",
    "                              )    \n",
    "    grid_search.fit(X_train, y_train)    \n",
    "\n",
    "    print('模型当前最优参数为:{}'.format(grid_search.best_params_))    \n",
    "    print('模型当前最优得分为:{}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af6f99-2d6a-4c9e-a2de-71c88448392a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "需要注意一下的是，除了获取下面的获取num_boost_round时候用的是原生的lightgbm（因为要用自带的cv）    \n",
    "下面配合GridSearchCV时必须使用sklearn接口的lightgbm。    \n",
    "\"\"\"    \n",
    "\"\"\"设置n_estimators 为581，调整num_leaves和max_depth，这里选择先粗调再细调\"\"\"    \n",
    "lgb_params = {'num_leaves': range(10, 80, 5), 'max_depth': range(3,10,2)}    \n",
    "get_best_cv_params(learning_rate=0.1, n_estimators=581, num_leaves=None, max_depth=None, min_data_in_leaf=20,    \n",
    "                   min_child_weight=0.001,bagging_fraction=1.0, feature_fraction=1.0, bagging_freq=0,    \n",
    "                   min_split_gain=0, reg_lambda=0, reg_alpha=0, param_grid=lgb_params)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929eece9-4ac5-48ed-8baf-004ae334ce9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"num_leaves为30，max_depth为5，进一步细调num_leaves和max_depth\"\"\"    \n",
    "lgb_params = {'num_leaves': range(25, 35, 1), 'max_depth': range(3,7,1)}    \n",
    "get_best_cv_params(learning_rate=0.1, n_estimators=85, num_leaves=None, max_depth=None, min_data_in_leaf=20,    \n",
    "                   min_child_weight=0.001,bagging_fraction=1.0, feature_fraction=1.0, bagging_freq=0,    \n",
    "                   min_split_gain=0, reg_lambda=0, reg_alpha=0, param_grid=lgb_params)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18623e21-9f61-41e8-a433-abb2fbc4a098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "确定num_leaves为33，max_depth为6 ，下面进行bagging_fraction、feature_fraction和bagging_freq的调参    \n",
    "\"\"\"    \n",
    "lgb_params = {'bagging_fraction': [i/10 for i in range(5,10,1)],    \n",
    "              'feature_fraction': [i/10 for i in range(5,10,1)],    \n",
    "              'bagging_freq': range(0,81,10)    \n",
    "             }    \n",
    "get_best_cv_params(learning_rate=0.1, n_estimators=85, num_leaves=33, max_depth=6, min_data_in_leaf=45,    \n",
    "                   min_child_weight=0.001,bagging_fraction=None, feature_fraction=None, bagging_freq=None,    \n",
    "                   min_split_gain=0, reg_lambda=0, reg_alpha=0, param_grid=lgb_params)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64fc8e8-c15e-4f79-b3ef-16c5f4aa0bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "确定bagging_fraction为0.9、feature_fraction为0.9、bagging_freq为10 ，下面进行reg_lambda、reg_alpha的调参    \n",
    "\"\"\"    \n",
    "lgb_params = {'reg_lambda': [0,0.001,0.01,0.03,0.08,0.3,0.5], 'reg_alpha': [0,0.001,0.01,0.03,0.08,0.3,0.5]}    \n",
    "get_best_cv_params(learning_rate=0.1, n_estimators=85, num_leaves=33, max_depth=6, min_data_in_leaf=45,    \n",
    "                   min_child_weight=0.001,bagging_fraction=0.9, feature_fraction=0.9, bagging_freq=10,    \n",
    "                   min_split_gain=0, reg_lambda=None, reg_alpha=None, param_grid=lgb_params)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86263aa6-3f1a-4fa7-a94b-cc2f7d4fe91d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "确定reg_lambda为0.01，reg_alpha为0.08，下面进行min_split_gain的调参    \n",
    "\"\"\"    \n",
    "lgb_params = {'min_split_gain': [i/10 for i in range(0,11,1)]}    \n",
    "get_best_cv_params(learning_rate=0.1, n_estimators=85, num_leaves=33, max_depth=6, min_data_in_leaf=45,    \n",
    "                   min_child_weight=0.001,bagging_fraction=0.9, feature_fraction=0.9, bagging_freq=10,    \n",
    "                   min_split_gain=0, reg_lambda=0.01, reg_alpha=0.08, param_grid=lgb_params) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049b3171-dfbe-4002-91e9-ff8c2b7a3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b25200-6db7-4774-b7c5-29148f32af43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "参数确定好了以后，我们设置一个比较小的learning_rate 0.01，来确定最终的num_boost_round    \n",
    "\"\"\"    \n",
    "# 设置5折交叉验证    \n",
    "# cv_fold = StratifiedKFold(n_splits=5, random_state=0, shuffle=True, )    \n",
    "final_params = {\n",
    "                'boosting_type': 'gbdt',    \n",
    "                'learning_rate': 0.01,    \n",
    "                'num_leaves': 33,    \n",
    "                'max_depth': 6,    \n",
    "                'min_data_in_leaf':45,    \n",
    "                'min_child_weight':0.001,    \n",
    "                'bagging_fraction': 0.9,    \n",
    "                'feature_fraction': 0.9,    \n",
    "                'bagging_freq': 10,    \n",
    "                'min_split_gain': 0.1,    \n",
    "                'reg_lambda':0.01,    \n",
    "                'reg_alpha':0.08,    \n",
    "                'nthread': 6    \n",
    "               }    \n",
    "lgb_train = lgb.Dataset(train_x, train_y)\n",
    "\n",
    "cv_result = lgb.cv(train_set=lgb_train,    \n",
    "                   early_stopping_rounds=20,    \n",
    "                   num_boost_round=5000,    \n",
    "                   nfold=5,    \n",
    "                   stratified=True,    \n",
    "                   shuffle=True,    \n",
    "                   params=final_params,    \n",
    "                   metrics='auc',    \n",
    "                   seed=0,    \n",
    "                  )    \n",
    "\n",
    "print('迭代次数{}'.format(len(cv_result['auc-mean'])))    \n",
    "print('交叉验证的AUC为{}'.format(max(cv_result['auc-mean'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b57a0-45f1-429d-8f23-c67035cdb67f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#根据最佳参数进行模型训练\n",
    "final_params = {\n",
    "                'boosting_type': 'gbdt',    \n",
    "                'learning_rate': 0.01,    \n",
    "                'num_leaves': 33,    \n",
    "                'max_depth': 6,    \n",
    "                'min_data_in_leaf':45,    \n",
    "                'min_child_weight':0.001,    \n",
    "                'bagging_fraction': 0.9,    \n",
    "                'feature_fraction': 0.9,    \n",
    "                'bagging_freq': 10,    \n",
    "                'min_split_gain': 0.1,    \n",
    "                'reg_lambda':0.01,    \n",
    "                'reg_alpha':0.08,    \n",
    "                'nthread': 6    \n",
    "               } \n",
    "\n",
    "train_x,test_x,train_y,test_y = train_test_split(train_x,train_y,test_size=0.2,random_state=42)\n",
    "\n",
    "train_matrix = lgb.Dataset(train_x, label=train_y)    \n",
    "valid_matrix = lgb.Dataset(test_x, label=test_y)\n",
    "    \n",
    "final_model_lgb = lgb.train(final_params, train_set = train_matrix, valid_sets = valid_matrix, num_boost_round=3753, verbose_eval=1000, early_stopping_rounds=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb63980-e8ba-4b1f-82c2-89c017bcc64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"预测\"\"\"    \n",
    "pred_y = final_model_lgb.predict(test_x) \n",
    "test_y = test_y.values\n",
    "#计算准确率\n",
    "accuracy = accuracy_score(test_y,pred_y)\n",
    "print('accuracy:%3.f%%'%(accuracy*100))\n",
    "\n",
    "\"\"\"计算roc的相关指标\"\"\"\n",
    "fpr, tpr, threshold = metrics.roc_curve(test_y, pred_y)    \n",
    "roc_auc = metrics.auc(fpr, tpr)    \n",
    "print('调参后lightgbm单模型在验证集上的AUC：{}'.format(roc_auc))    \n",
    "\"\"\"画出roc曲线图\"\"\"    \n",
    "plt.figure(figsize=(8, 8))    \n",
    "plt.title('Validation ROC')    \n",
    "plt.plot(fpr, tpr, 'b', label = 'Val AUC = %0.4f' % roc_auc)    \n",
    "plt.ylim(0,1)    \n",
    "plt.xlim(0,1)    \n",
    "plt.legend(loc='best')    \n",
    "plt.title('ROC')    \n",
    "plt.ylabel('True Positive Rate')    \n",
    "plt.xlabel('False Positive Rate')    \n",
    "# 画出对角线    \n",
    "plt.plot([0,1],[0,1],'r--')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d8564-9e08-4a87-92b3-220a1c2f2de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b18569-611f-49d5-aea6-c899167d40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用最佳模型预测结果\n",
    "lgb_result = final_model_lgb.predict(valid_x)\n",
    "#结果保存\n",
    "# lgb_result.to_pickle('lgb_result.pickle')\n",
    "#submit结果拼接\n",
    "lgb_submit = pd.DataFrame([[data_test_a['id'][i], lgb_test[i]] for i in range(len(lgb_test))], columns=['id', 'isDefault'])\n",
    "lgb_submit.to_csv('lgb_test2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd020b86-5cd6-48ba-a4b7-a790cc41c085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292dc9e-c59c-48cd-8ba7-78a6381c84ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
