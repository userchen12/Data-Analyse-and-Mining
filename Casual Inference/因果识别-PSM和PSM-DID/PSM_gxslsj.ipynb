{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psmatching in d:\\anaconda3\\lib\\site-packages (0.1.dev21)\n",
      "Requirement already satisfied: statsmodels in d:\\anaconda3\\lib\\site-packages (from psmatching) (0.10.0)\n",
      "Requirement already satisfied: pandas in d:\\anaconda3\\lib\\site-packages (from psmatching) (0.24.2)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (from psmatching) (1.16.4)\n",
      "Requirement already satisfied: scipy in d:\\anaconda3\\lib\\site-packages (from psmatching) (1.2.1)\n",
      "Requirement already satisfied: patsy>=0.4.0 in d:\\anaconda3\\lib\\site-packages (from statsmodels->psmatching) (0.5.1)\n",
      "Requirement already satisfied: pytz>=2011k in d:\\anaconda3\\lib\\site-packages (from pandas->psmatching) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in d:\\anaconda3\\lib\\site-packages (from pandas->psmatching) (2.8.0)\n",
      "Requirement already satisfied: six in d:\\anaconda3\\lib\\site-packages (from patsy>=0.4.0->statsmodels->psmatching) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spyder 3.3.6 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "xlwings 0.15.8 has requirement pywin32>=224, but you'll have pywin32 223 which is incompatible.\n",
      "spyder 3.3.6 has requirement pyqt5<5.13; python_version >= \"3\", but you'll have pyqt5 5.13.2 which is incompatible.\n",
      "mysql-connector-python 8.0.19 has requirement protobuf==3.6.1, but you'll have protobuf 3.8.0 which is incompatible.\n",
      "You are using pip version 10.0.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# 安装psmatching包\n",
    "!pip install psmatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psmatching.match as psm\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from psmatching.utilities import *\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#地址\n",
    "path = \"./data/psm/psm_gxslsj_data.csv\"\n",
    "#model由干预项和其他类别标签组成，形式为\"干预项~类别特征+列别特征。。。\"\n",
    "model = \"PUSH ~ AGE + SEX + VIP_LEVEL + LASTDAY_BUY_DIFF + PREFER_TYPE + LOGTIME_PREFER + USE_COUPON_BEFORE + ACTIVE_LEVEL\"\n",
    "#想要几个匹配项，如k=3，那一个push=1的用户就会匹配三个push=0的近似用户\n",
    "k = \"3\"\n",
    "m = psm.PSMatch(path, model, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "计算倾向性匹配得分 ... \n",
      "计算完成!\n"
     ]
    }
   ],
   "source": [
    "# 获得倾向性匹配得分\n",
    "df = pd.read_csv(path)\n",
    "#将用户ID作为数据的新索引\n",
    "df = df.set_index(\"ID\")\n",
    "print(\"\\n计算倾向性匹配得分 ...\", end = \" \")\n",
    "#利用逻辑回归框架计算倾向得分，即广义线性估计 + 二项式Binomial\n",
    "glm_binom = sm.formula.glm(formula = model, data = df, family = sm.families.Binomial())\n",
    "#拟合拟合给定family的广义线性模型\n",
    "#https://www.w3cschool.cn/doc_statsmodels/statsmodels-generated-statsmodels-genmod-generalized_linear_model-glm-fit.html?lang=en\n",
    "result = glm_binom.fit()\n",
    "# 输出回归分析的摘要\n",
    "# print(result.summary)\n",
    "propensity_scores = result.fittedvalues\n",
    "print(\"\\n计算完成!\")\n",
    "#将倾向性匹配得分写入data\n",
    "df[\"PROPENSITY\"] = propensity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groups是干预项，propensity是倾向性匹配得分，这里要分开干预与非干预，且确保n1<n2\n",
    "#注意：将PUSH替换成自己的干预项\n",
    "groups = df.PUSH\n",
    "propensity = df.PROPENSITY\n",
    "#把干预项替换成True和False\n",
    "groups = groups == groups.unique()[1]\n",
    "n = len(groups)\n",
    "#计算True和False的数量\n",
    "n1 = groups[groups==1].sum()\n",
    "n2 = n-n1\n",
    "g1, g2 = propensity[groups==1], propensity[groups==0]\n",
    "#确保n2>n1，,少的匹配多的，否则交换下\n",
    "if n1 > n2:\n",
    "    n1, n2, g1, g2 = n2, n1, g2, g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机排序干预组，减少原始排序的影响\n",
    "m_order = list(np.random.permutation(groups[groups==1].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "给每个干预组匹配 [3] 个对照组 ...  \n",
      "匹配完成!\n"
     ]
    }
   ],
   "source": [
    "# 根据倾向评分差异将干预组与对照组进行匹配\n",
    "# 注意：caliper = None可以替换成自己想要的精度\n",
    "matches = {}\n",
    "k = int(k)\n",
    "print(\"\\n给每个干预组匹配 [\" + str(k) + \"] 个对照组 ... \", end = \" \")\n",
    "for m in m_order:\n",
    "    # 计算所有倾向得分差异,这里用了最粗暴的绝对值\n",
    "    # 将propensity[groups==1]分别拿出来，每一个都与所有的propensity[groups==0]相减\n",
    "    dist = abs(g1[m]-g2)\n",
    "    array = np.array(dist)\n",
    "    #如果无放回地匹配，最后会出现要选取3个匹配对象，但是只有一个候选对照组的错误，故进行判断\n",
    "    if k < len(array):\n",
    "        # 在array里面选择K个最小的数字，并转换成列表\n",
    "        k_smallest = np.partition(array, k)[:k].tolist()\n",
    "        # 用卡尺做判断\n",
    "        caliper = None\n",
    "        if caliper:\n",
    "            caliper = float(caliper)\n",
    "            # 判断k_smallest是否在定义的卡尺范围\n",
    "            keep_diffs = [i for i in k_smallest if i <= caliper]\n",
    "            keep_ids = np.array(dist[dist.isin(keep_diffs)].index)\n",
    "        else:\n",
    "            # 如果不用标尺判断，那就直接上k_smallest了\n",
    "            keep_ids = np.array(dist[dist.isin(k_smallest)].index)\n",
    "        #  如果keep_ids比要匹配的数量多，那随机选择下，如要少，通过补NA配平数量\n",
    "        if len(keep_ids) > k:\n",
    "            matches[m] = list(np.random.choice(keep_ids, k, replace=False))\n",
    "        elif len(keep_ids) < k:\n",
    "            while len(matches[m]) <= k:\n",
    "                matches[m].append(\"NA\")\n",
    "        else:\n",
    "            matches[m] = keep_ids.tolist()\n",
    "        # 判断 replace 是否放回\n",
    "        replace = False\n",
    "        if not replace:\n",
    "            g2 = g2.drop(matches[m])\n",
    "print(\"\\n匹配完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将匹配完成的结果合并起来\n",
    "matches = pd.DataFrame.from_dict(matches, orient=\"index\")\n",
    "matches = matches.reset_index()\n",
    "column_names = {}\n",
    "column_names[\"index\"] = \"干预组\"\n",
    "for i in range(k):\n",
    "    column_names[i] = str(\"匹配对照组_\" + str(i+1))\n",
    "matches = matches.rename(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从全部data中提取干预组和匹配对照的数据\n",
    "# 这里直接调用get_matched_data，注意输入的matches是匹配结果，df是全部数据\n",
    "matched_data = get_matched_data(matches, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "将倾向性匹配得分写入到文档 ... 完成!\n",
      "将匹配结果写入到文档 ... 完成!\n"
     ]
    }
   ],
   "source": [
    "# 将结果数据写入到文档\n",
    "# 注意：可以自己更改地址\n",
    "print(\"将倾向性匹配得分写入到文档 ...\", end = \" \")\n",
    "save_file = path.split(\".\")[0] + \"_倾向性匹配得分.csv\"\n",
    "df.to_csv(save_file, index = False)\n",
    "print(\"完成!\")\n",
    "print(\"将匹配结果写入到文档 ...\", end = \" \")\n",
    "save_file = path.split(\".\")[0] + \"_匹配结果.csv\"\n",
    "matches.to_csv(save_file, index = False)\n",
    "print(\"完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始评估匹配 ...\n",
      "\tAGE(0.9904): 通过\n",
      "\tSEX(0.6688): 通过\n",
      "\tVIP_LEVEL(0.0089): 未通过\n",
      "\tLASTDAY_BUY_DIFF(0.5134): 通过\n",
      "\tPREFER_TYPE(0.7107): 通过\n",
      "\tLOGTIME_PREFER(0.2442): 通过\n",
      "\tUSE_COUPON_BEFORE(0.2961): 通过\n",
      "\tACTIVE_LEVEL(0.7934): 通过\n",
      "\n",
      "变量未全部通过匹配\n"
     ]
    }
   ],
   "source": [
    "# 获取变量进行分析\n",
    "variables = df.columns.tolist()[0:-2]\n",
    "results = {}\n",
    "print(\"开始评估匹配 ...\")\n",
    "\n",
    "#注意：将PUSH替换成自己的干预项\n",
    "for var in variables:\n",
    "        # 制作用于卡方检验的频率计数交叉表\n",
    "    crosstable = pd.crosstab(df['PUSH'],df[var])\n",
    "    if len(df[var].unique().tolist()) <= 2:\n",
    "        # 计算 2x2 表的卡方统计量、df 和 p 值\n",
    "        p_val = calc_chi2_2x2(crosstable)[1]\n",
    "    else:\n",
    "        # 计算 2x2 表的卡方统计量、df 和 p 值\n",
    "        p_val = calc_chi2_2xC(crosstable)[1]\n",
    "    results[var] = p_val\n",
    "    print(\"\\t\" + var + '(' + str(p_val) + ')', end = \"\")\n",
    "    if p_val < 0.05:\n",
    "        print(\": 未通过\")\n",
    "    else:\n",
    "        print(\": 通过\")\n",
    "\n",
    "if True in [i < 0.05 for i in results.values()]:\n",
    "    print(\"\\n变量未全部通过匹配\")\n",
    "else:\n",
    "    print(\"\\n变量全部通过匹配\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
