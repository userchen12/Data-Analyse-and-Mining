{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a30a557-cf2a-4f16-8070-53e26942ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9142ac4-f544-4ff2-8156-cd7ae047f1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'median_house_value', 'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'..\\..\\..\\数据集\\handson-ml2\\datasets\\housing\\housing.csv'\n",
    "origin_data = pd.read_csv(path)\n",
    "origin_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d6cceb-df8f-4413-ad44-440e84f9c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = origin_data.drop('median_house_value', axis=1)\n",
    "df_labels = origin_data['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11546f51-6028-4b71-aaaa-ffead6b99cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#data clean\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d66a237-05af-4330-bf84-7ad17910e9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20640 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "# so we need fill na in total_bedrooms, now we use median\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "# only fill na in int or float by imputer\n",
    "# fit just calculate the median of all columns and store the result in statistics\n",
    "df_num = df.drop('ocean_proximity', axis=1)\n",
    "imputer.fit(df_num)\n",
    "imputer.statistics_\n",
    "# auto fill na in all num column\n",
    "X = imputer.transform(df_num)\n",
    "df_tr = pd.DataFrame(X, columns=df_num.columns, index=df_num.index)\n",
    "df_tr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23171d2e-6b2d-484a-a1e8-89c02c03acf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# onehot cat feature\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "df_cat = df[['ocean_proximity']]\n",
    "df_cat_onehot = cat_encoder.fit_transform(df_cat)\n",
    "df_cat_onehot.toarray()\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24fa4a4-3227-42dc-944f-a83289f948ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pipeline to complete data transform\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombineAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = True\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix]/X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#except for last one, other function should have fit_transform()\n",
    "num_pipeline = Pipeline([\n",
    "    ('impyter', SimpleImputer(strategy='median')),\n",
    "    ('attribs_adder', CombineAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_att = list(df_num)\n",
    "cat_att = ['ocean_proximity']\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_att),\n",
    "    ('cat', OneHotEncoder(), cat_att),\n",
    "])\n",
    "\n",
    "df_prepared = full_pipeline.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cd530ab-3518-4726-a25d-957247ec1a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68286.12607251323"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use LR to train\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(df_prepared, df_labels)\n",
    "\n",
    "# use mean_squard_error() to evaluate model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lr_predictions = lr.predict(df_prepared)\n",
    "lr_rmse = np.sqrt(mean_squared_error(df_labels, lr_predictions))\n",
    "lr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "685b8770-580c-4081-9c6a-fbb6ea5282ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use DecisionTree\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tr = DecisionTreeRegressor()\n",
    "tr.fit(df_prepared, df_labels)\n",
    "tr_predictions = tr.predict(df_prepared)\n",
    "tr_rmse = np.sqrt(mean_squared_error(df_labels, tr_predictions))\n",
    "tr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95e962f7-6cdb-4aef-bf06-7f5be78ceb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [119244.11923308  72670.26091891  83677.92775679  74475.10327736\n",
      "  89827.21027774  77655.70647366  68985.55446203  99509.57244364\n",
      "  95480.19636218  72557.02651923]\n",
      "Mean: 85408.2677724617\n",
      "Standard deviation: 14981.42028594353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tr, df_prepared, df_labels, scoring='neg_mean_squared_error', cv=10)\n",
    "tr_mse_scores = np.sqrt(-scores)\n",
    "def display_scores(scores):\n",
    "    print('Scores:', scores)\n",
    "    print('Mean:', scores.mean())\n",
    "    print('Standard deviation:', scores.std())\n",
    "    \n",
    "display_scores(tr_mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcd24976-b091-4b2c-8e72-e4d4810f7c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [8.41836630e+04 6.11915285e+04 8.67436096e+04 6.22867345e+04\n",
      " 6.55810502e+15 6.89185866e+04 5.25048641e+04 9.09042279e+04\n",
      " 7.76750890e+04 5.39409537e+04]\n",
      "Mean: 655810502198756.0\n",
      "Standard deviation: 1967431506383484.8\n"
     ]
    }
   ],
   "source": [
    "# compare with lr\n",
    "lr_scores = cross_val_score(lr, df_prepared, df_labels, scoring='neg_mean_squared_error', cv=10)\n",
    "lr_mse_scores = np.sqrt(-lr_scores)\n",
    "display_scores(lr_mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23471b6b-0ef2-4243-ad07-6bacdccacc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [97615.38436898 47257.43109551 65519.70300793 56448.15282712\n",
      " 61143.31121477 59737.75942911 47317.60103882 79591.49611091\n",
      " 74258.72253331 49262.471588  ]\n",
      "Mean: 63815.20332144628\n",
      "Standard deviation: 15295.315485184134\n"
     ]
    }
   ],
   "source": [
    "# user RandomForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(df_prepared, df_labels)\n",
    "rf_scores = cross_val_score(rf, df_prepared, df_labels, scoring='neg_mean_squared_error', cv=10)\n",
    "rf_mse_scores = np.sqrt(-rf_scores)\n",
    "display_scores(rf_mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d972111a-5980-4ea0-90d0-61c20f8879a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mode result\n",
    "import joblib\n",
    "joblib.dumps(rf, 'rf.pkl')\n",
    "# load\n",
    "# model_loaded = joblib.load('rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2ef01be-c39d-4975-821e-fa4fd27c4410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 6, 'n_estimators': 30}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and use SearchCV to adjust parameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators':[3, 10, 30], 'max_features':[2, 4, 6, 8]},\n",
    "    {'bootstrap':[False], 'n_estimators':[3, 10], 'max_features':[2, 3, 4]}\n",
    "]\n",
    "\n",
    "rf_grid = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf_grid, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(df_prepared, df_labels)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d8b3a69-8198-4c9a-91a1-836dd9fea6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82453.76559972462 {'max_features': 2, 'n_estimators': 3}\n",
      "71499.5988553603 {'max_features': 2, 'n_estimators': 10}\n",
      "69697.47482116584 {'max_features': 2, 'n_estimators': 30}\n",
      "76674.14545524534 {'max_features': 4, 'n_estimators': 3}\n",
      "71382.9640741928 {'max_features': 4, 'n_estimators': 10}\n",
      "68308.43508283746 {'max_features': 4, 'n_estimators': 30}\n",
      "75455.45310532284 {'max_features': 6, 'n_estimators': 3}\n",
      "71282.21843505515 {'max_features': 6, 'n_estimators': 10}\n",
      "68048.81374128729 {'max_features': 6, 'n_estimators': 30}\n",
      "76487.10339007161 {'max_features': 8, 'n_estimators': 3}\n",
      "71344.07267106822 {'max_features': 8, 'n_estimators': 10}\n",
      "68399.23608320835 {'max_features': 8, 'n_estimators': 30}\n",
      "78896.41367236938 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "71593.54857189515 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "76809.27048981508 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "71143.01941529459 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "76680.79933439026 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "72089.8688637956 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "#score\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17dcab5b-a652-4413-a2fb-ce2cb4245b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3023489818914827, 'median_income'),\n",
       " (0.16172338991642146, 'INLAND'),\n",
       " (0.10791115752561373, 'pop_per_hhold'),\n",
       " (0.08910919337840666, 'bedromm_per_room'),\n",
       " (0.07315586848726109, 'longitude'),\n",
       " (0.06917737003841141, 'rooms_per_hhold'),\n",
       " (0.06696331974952748, 'latitude'),\n",
       " (0.04356847031401048, 'housing_median_age'),\n",
       " (0.01705448418120849, 'total_rooms'),\n",
       " (0.017022601746209797, 'total_bedrooms'),\n",
       " (0.017012407665773912, 'population'),\n",
       " (0.0153451576828215, 'households'),\n",
       " (0.01224089642541003, '<1H OCEAN'),\n",
       " (0.004533375501151367, 'NEAR OCEAN'),\n",
       " (0.002679422052134257, 'NEAR BAY'),\n",
       " (0.00015390344415570358, 'ISLAND')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show feature importance\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "cat_encoder = full_pipeline.named_transformers_['cat']\n",
    "cat_one_hot_att = list(cat_encoder.categories_[0])\n",
    "extra_att = ['rooms_per_hhold', 'pop_per_hhold', 'bedromm_per_room']\n",
    "\n",
    "atts = num_att+extra_att+cat_one_hot_att\n",
    "\n",
    "sorted(zip(feature_importances, atts), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b9f3874-342b-431f-b115-4c70a86c6c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19096.08712099313"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the final model\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = origin_data.drop('median_house_value', axis=1)\n",
    "y_test = origin_data[['median_house_value']]\n",
    "\n",
    "X_test_prepared = full_pipeline.fit_transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75daf37d-6768-4ae0-8664-41aaf634d925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a9ec2b0c-16d9-4d59-9b7c-544a1fae09c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18674.1938046 ],\n",
       "       [19508.85881884]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "confidence = 0.95\n",
    "final_predictions = final_predictions.reshape(final_predictions.shape[0],1)\n",
    "squard_errors = (final_predictions - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squard_errors)-1, loc=squard_errors.mean(), scale=stats.sem(squard_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74e91a3d-dfee-4c82-8921-e13b947f9c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109374.66591940311"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exerciese\n",
    "# 1.use svm model to train\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "svr_model = SVR(kernel='linear')\n",
    "svr_model.fit(df_prepared, df_labels)\n",
    "svr_scores =  cross_val_score(svr_model, df_prepared, df_labels, scoring='neg_mean_squared_error', cv=10)\n",
    "svr_scores = np.sqrt(-svr_scores)\n",
    "svr_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d02f307f-d442-4b69-9983-83c941d54510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 10, 'max_features': 6}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. use randomizesearch\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators':[3, 10, 30], 'max_features':[2, 4, 6, 8]},\n",
    "    {'bootstrap':[False], 'n_estimators':[3, 10], 'max_features':[2, 3, 4]}\n",
    "]\n",
    "\n",
    "rf_grid = RandomForestRegressor()\n",
    "grid_search = RandomizedSearchCV(rf_grid, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(df_prepared, df_labels)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "317c9572-fd2a-4137-b14f-1932134a3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. add a feature selection to pipeline\n",
    "# use pipeline to complete data transform\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombineAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = True\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix]/X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#except for last one, other function should have fit_transform()\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('attribs_adder', CombineAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_att = list(df_num)\n",
    "cat_att = ['ocean_proximity']\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_att),\n",
    "    ('cat', OneHotEncoder(), cat_att),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30c2bb51-1de6-483e-b1f5-6a922359f95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-55320.72002442, -56255.14933279,  13364.73984258,  -1882.43424613,\n",
       "         7465.2513185 , -46331.96946603,  45752.37330988,  74791.3185514 ,\n",
       "         6372.10036191,    863.34022157,   9613.21958474, -23233.9309243 ,\n",
       "       -60499.22193162, 129660.72058374, -27120.67833241, -18806.88939541])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(df_prepared, df_labels)\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "867ad9e3-3d1f-44b6-a7bf-dbbd882936a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  2.34476576,  0.        ,  1.05254828, -1.32783522],\n",
       "       [ 0.        ,  2.33223796,  0.        ,  1.04318455, -1.32284391],\n",
       "       [ 0.        ,  1.7826994 ,  0.        ,  1.03850269, -1.33282653],\n",
       "       ...,\n",
       "       [ 0.        , -1.14259331,  1.        ,  1.77823747, -0.8237132 ],\n",
       "       [ 0.        , -1.05458292,  1.        ,  1.77823747, -0.87362627],\n",
       "       [ 0.        , -0.78012947,  1.        ,  1.75014627, -0.83369581]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.create a totoal pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class FeatureSelection(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, k):\n",
    "        self.model = model\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.model.fit(X, y)\n",
    "        self.feature_importance = np.abs(self.model.coef_)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        indices = np.argsort(self.feature_importance)[::-1][:self.k]\n",
    "        features = X[:, indices]\n",
    "        return features\n",
    "\n",
    "k = 5\n",
    "selector = FeatureSelection(LinearRegression(), k)\n",
    "selected = selector.fit_transform(df_prepared, df_labels)\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e9bb39e-94cf-4636-b563-753c7d486d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('data_clean',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('attribs_adder',\n",
       "                                                                   CombineAttributesAdder()),\n",
       "                                                                  ('std_scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['longitude', 'latitude',\n",
       "                                                   'housing_median_age',\n",
       "                                                   'total_rooms',\n",
       "                                                   'total_bedrooms',\n",
       "                                                   'population', 'households',\n",
       "                                                   'median_income']),\n",
       "                                                 ('cat', OneHotEncoder(),\n",
       "                                                  ['ocean_proximity'])])),\n",
       "                ('feature_selection',\n",
       "                 FeatureSelection(k=5, model=LinearRegression())),\n",
       "                ('regressor', LinearRegression())])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add it to the pipeline\n",
    "total_pipeline = Pipeline([\n",
    "    ('data_clean', full_pipeline),\n",
    "    ('feature_selection', FeatureSelection(model=LinearRegression(), k=5)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "total_pipeline.fit(df, df_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a7f250-ddc4-487d-8115-5b800d518171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, concat the code\n",
    "\n",
    "rom sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "# data clean\n",
    "class CombineAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = True\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix]/X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImpute\n",
    "\n",
    "#except for last one, other function should have fit_transform()\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('attribs_adder', CombineAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "df_num = df.drop('ocean_proximity', axis=1)\n",
    "num_att = list(df_num)\n",
    "cat_att = ['ocean_proximity']\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_att),\n",
    "    ('cat', OneHotEncoder(), cat_att),\n",
    "])\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class FeatureSelection(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, k):\n",
    "        self.model = model\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.model.fit(X, y)\n",
    "        self.feature_importance = np.abs(self.model.coef_)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        indices = np.argsort(self.feature_importance)[::-1][:self.k]\n",
    "        features = X[:, indices]\n",
    "        return features\n",
    "    \n",
    "total_pipeline = Pipeline([\n",
    "    ('data_clean', full_pipeline),\n",
    "    ('feature_selection', FeatureSelection(model=LinearRegression(), k=5)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "total_pipeline.fit(df, df_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
